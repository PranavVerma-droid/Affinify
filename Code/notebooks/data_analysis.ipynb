{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb9f523",
   "metadata": {},
   "source": [
    "# Affinify: Protein-Ligand Binding Affinity Analysis\n",
    "\n",
    "This notebook demonstrates the data analysis and model development process for the Affinify project.\n",
    "\n",
    "## Overview\n",
    "- Load and explore sample binding affinity data\n",
    "- Perform molecular descriptor analysis\n",
    "- Train and evaluate machine learning models\n",
    "- Visualize results and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üß¨ Affinify Analysis Notebook\")\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430fc27d",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a03210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "try:\n",
    "    from data_processing.data_collector import DataCollector\n",
    "    \n",
    "    # Create sample dataset\n",
    "    collector = DataCollector()\n",
    "    df = collector.create_sample_dataset()\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    df.head()\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Creating placeholder data...\")\n",
    "    \n",
    "    # Create placeholder data\n",
    "    df = pd.DataFrame({\n",
    "        'protein_name': ['Protein A', 'Protein B', 'Protein C'] * 10,\n",
    "        'ligand_smiles': ['CCO', 'C1CCCCC1', 'c1ccccc1'] * 10,\n",
    "        'binding_affinity_nm': np.random.lognormal(2, 1, 30),\n",
    "        'pKd': np.random.normal(6.5, 1, 30),\n",
    "        'mol_weight': np.random.normal(350, 100, 30),\n",
    "        'logp': np.random.normal(2.5, 1.5, 30)\n",
    "    })\n",
    "    \n",
    "    print(\"Created placeholder dataset\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e566e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"üìä Dataset Statistics\")\n",
    "print(\"=\" * 25)\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"Unique proteins: {df['protein_name'].nunique()}\")\n",
    "print(f\"Binding affinity range: {df['binding_affinity_nm'].min():.1f} - {df['binding_affinity_nm'].max():.1f} nM\")\n",
    "print(f\"pKd range: {df['pKd'].min():.2f} - {df['pKd'].max():.2f}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nüîç Missing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f44d02",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Binding affinity distribution\n",
    "axes[0,0].hist(df['binding_affinity_nm'], bins=20, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_xlabel('Binding Affinity (nM)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].set_title('Distribution of Binding Affinities')\n",
    "axes[0,0].set_yscale('log')\n",
    "\n",
    "# 2. pKd distribution\n",
    "axes[0,1].hist(df['pKd'], bins=20, alpha=0.7, color='lightcoral')\n",
    "axes[0,1].set_xlabel('pKd')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].set_title('Distribution of pKd Values')\n",
    "\n",
    "# 3. Protein distribution\n",
    "protein_counts = df['protein_name'].value_counts()\n",
    "axes[1,0].bar(range(len(protein_counts)), protein_counts.values, color='lightgreen')\n",
    "axes[1,0].set_xticks(range(len(protein_counts)))\n",
    "axes[1,0].set_xticklabels(protein_counts.index, rotation=45, ha='right')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].set_title('Records per Protein')\n",
    "\n",
    "# 4. Molecular weight vs binding affinity\n",
    "if 'mol_weight' in df.columns:\n",
    "    scatter = axes[1,1].scatter(df['mol_weight'], df['binding_affinity_nm'], \n",
    "                              c=df['pKd'], cmap='viridis', alpha=0.6)\n",
    "    axes[1,1].set_xlabel('Molecular Weight (Da)')\n",
    "    axes[1,1].set_ylabel('Binding Affinity (nM)')\n",
    "    axes[1,1].set_title('Molecular Weight vs Binding Affinity')\n",
    "    axes[1,1].set_yscale('log')\n",
    "    plt.colorbar(scatter, ax=axes[1,1], label='pKd')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20be6ce",
   "metadata": {},
   "source": [
    "## Molecular Descriptor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce701ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze molecular descriptors\n",
    "try:\n",
    "    from data_processing.molecular_processor import LigandProcessor\n",
    "    \n",
    "    processor = LigandProcessor()\n",
    "    \n",
    "    # Calculate descriptors for first few SMILES\n",
    "    sample_smiles = df['ligand_smiles'].head(5).tolist()\n",
    "    \n",
    "    descriptor_data = []\n",
    "    for smiles in sample_smiles:\n",
    "        descriptors = processor.smiles_to_descriptors(smiles)\n",
    "        descriptors['smiles'] = smiles\n",
    "        descriptor_data.append(descriptors)\n",
    "    \n",
    "    descriptor_df = pd.DataFrame(descriptor_data)\n",
    "    print(\"üß™ Molecular Descriptors (Sample):\")\n",
    "    print(descriptor_df.round(3))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Molecular processor not available - skipping descriptor analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdcfbae",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d9919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f')\n",
    "plt.title('Correlation Matrix of Molecular Properties')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show strongest correlations with binding affinity\n",
    "if 'binding_affinity_nm' in correlation_matrix.columns:\n",
    "    affinity_corr = correlation_matrix['binding_affinity_nm'].abs().sort_values(ascending=False)\n",
    "    print(\"\\nüîç Strongest correlations with binding affinity:\")\n",
    "    print(affinity_corr.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d3b50a",
   "metadata": {},
   "source": [
    "## Machine Learning Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for machine learning\n",
    "try:\n",
    "    from data_processing.pipeline import DataPipeline\n",
    "    from models.traditional_models import BindingAffinityPredictor\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipeline = DataPipeline()\n",
    "    \n",
    "    # Preprocess data\n",
    "    processed_df = pipeline.preprocess_binding_data(df)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X, y = pipeline.prepare_features_and_target(processed_df)\n",
    "    \n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    print(f\"Feature columns: {list(X.columns)}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"ML modules not available: {e}\")\n",
    "    print(\"Creating simple feature matrix...\")\n",
    "    \n",
    "    # Simple feature preparation\n",
    "    feature_cols = [col for col in df.columns if col in ['mol_weight', 'logp'] and col in df.columns]\n",
    "    if feature_cols:\n",
    "        X = df[feature_cols].fillna(0)\n",
    "        y = df['pKd'] if 'pKd' in df.columns else df['binding_affinity_nm']\n",
    "        print(f\"Simple features: {feature_cols}\")\n",
    "    else:\n",
    "        print(\"No suitable features found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple model\n",
    "if 'X' in locals() and 'y' in locals() and len(X) > 0:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import r2_score, mean_squared_error\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train Random Forest model\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = rf_model.predict(X_train)\n",
    "    y_pred_test = rf_model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    \n",
    "    print(\"ü§ñ Random Forest Model Results:\")\n",
    "    print(f\"Training R¬≤: {train_r2:.3f}\")\n",
    "    print(f\"Test R¬≤: {test_r2:.3f}\")\n",
    "    print(f\"Training RMSE: {train_rmse:.3f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.3f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    if hasattr(rf_model, 'feature_importances_'):\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': rf_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nüìä Feature Importance:\")\n",
    "        print(importance_df)\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(importance_df['feature'], importance_df['importance'])\n",
    "        plt.xlabel('Importance')\n",
    "        plt.title('Feature Importance in Random Forest Model')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No data available for model training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53086481",
   "metadata": {},
   "source": [
    "## Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "if 'y_test' in locals() and 'y_pred_test' in locals():\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Scatter plot of predictions vs actual\n",
    "    plt.scatter(y_test, y_pred_test, alpha=0.6, color='blue', label='Predictions')\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(y_test.min(), y_pred_test.min())\n",
    "    max_val = max(y_test.max(), y_pred_test.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', \n",
    "             label='Perfect Prediction', linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'Predicted vs Actual Values (R¬≤ = {test_r2:.3f})')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add text with metrics\n",
    "    plt.text(0.05, 0.95, f'R¬≤ = {test_r2:.3f}\\nRMSE = {test_rmse:.3f}', \n",
    "             transform=plt.gca().transAxes, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "             verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Residuals plot\n",
    "    residuals = y_test - y_pred_test\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_pred_test, residuals, alpha=0.6, color='green')\n",
    "    plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residuals Plot')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No predictions available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff949d9f",
   "metadata": {},
   "source": [
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce06edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Analysis Summary\")\n",
    "print(\"=\" * 25)\n",
    "print(f\"Dataset size: {len(df)} records\")\n",
    "print(f\"Number of unique proteins: {df['protein_name'].nunique()}\")\n",
    "print(f\"Binding affinity range: {df['binding_affinity_nm'].min():.1f} - {df['binding_affinity_nm'].max():.1f} nM\")\n",
    "\n",
    "if 'test_r2' in locals():\n",
    "    print(f\"\\nü§ñ Model Performance:\")\n",
    "    print(f\"Test R¬≤: {test_r2:.3f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.3f}\")\n",
    "    \n",
    "    if test_r2 > 0.7:\n",
    "        print(\"‚úÖ Model achieves target performance (R¬≤ > 0.7)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Model performance below target - consider feature engineering\")\n",
    "\n",
    "print(\"\\nüìù Next Steps:\")\n",
    "print(\"1. Collect more diverse training data\")\n",
    "print(\"2. Implement advanced feature engineering\")\n",
    "print(\"3. Try ensemble models and hyperparameter tuning\")\n",
    "print(\"4. Validate on external test sets\")\n",
    "print(\"5. Deploy model in production application\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf312c93",
   "metadata": {},
   "source": [
    "## Interactive Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction function\n",
    "def predict_binding_affinity(mol_weight=350, logp=2.5):\n",
    "    \"\"\"Make a prediction for given molecular properties.\"\"\"\n",
    "    if 'rf_model' in locals() and hasattr(rf_model, 'predict'):\n",
    "        # Create feature vector\n",
    "        features = np.array([[mol_weight, logp]])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = rf_model.predict(features)[0]\n",
    "        \n",
    "        print(f\"Input: MW = {mol_weight:.1f} Da, LogP = {logp:.2f}\")\n",
    "        print(f\"Predicted pKd: {prediction:.2f}\")\n",
    "        print(f\"Predicted binding affinity: {10**(-prediction) * 1e9:.1f} nM\")\n",
    "        \n",
    "        return prediction\n",
    "    else:\n",
    "        print(\"No trained model available\")\n",
    "        return None\n",
    "\n",
    "# Example predictions\n",
    "print(\"üß™ Example Predictions:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "examples = [\n",
    "    (300, 2.0),   # Small, hydrophilic\n",
    "    (400, 3.5),   # Medium, moderate lipophilicity  \n",
    "    (500, 5.0)    # Large, lipophilic\n",
    "]\n",
    "\n",
    "for mw, lp in examples:\n",
    "    predict_binding_affinity(mw, lp)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
